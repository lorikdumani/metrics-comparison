Id;PostId;UserId;PostHistoryTypeId;RevisionGUID;CreationDate;Text;UserDisplayName;Comment
66218038;23943004;1329652;2;709c1a29-3ad4-429e-a2d8-7bdd708fef3a;2014-05-29 21:05:48.0;"Here's what I would do, in guesstimated order of importance:&#xD;&#xA;&#xD;&#xA;5. Return the floating-point from the `Point` class by value, not by reference.&#xD;&#xA;4. Use `coords[i]` instead of `coords.at(i)`, since you *already* assert that it's within bounds. The `at` member checks the bounds. You only need to check it once.&#xD;&#xA;3. Replace the home-baked error indication/checking in the `Point::operator[]` with an assert. That's what asserts are for, and I doubt that you need to check in release code.&#xD;&#xA;2. Replace the repeated division with a single division and repeated multiplication.&#xD;&#xA;1. Use Adam Bartha's recommendation for `memset`.&#xD;&#xA;&#xD;&#xA;With all this, the `Point::operator[]` will have a chance of getting inlined in the release build and can reduce to two machine instructions (effective address computation and floating point load). That's what you want. Of course it must be *defined* in the header fine, otherwise the inlining will only be performed if you enable link-time code generation (a.k.a. LTO).&#xD;&#xA;&#xD;&#xA;<!-- -->&#xD;&#xA;&#xD;&#xA;    FT Point::operator[](int i) const {&#xD;&#xA;      assert(i >= 0 && i < (int)coords.size());&#xD;&#xA;      return coords[i];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    void compute_variances(size_t t, const std::vector<Point>& points, float* avg,&#xD;&#xA;                           float* var, size_t* split_dims) {&#xD;&#xA;      memset(memset((void*)avg, 0, points[0].dim() * sizeof(float));&#xD;&#xA;    &#xD;&#xA;      for (size_t i = 0; i < points.size(); ++i) {&#xD;&#xA;        float const i_n = 1.0/(1.0 + i);&#xD;&#xA;        for (size_t d = 0; d < points[0].dim(); ++d) {&#xD;&#xA;          float const delta = points[i][d] - avg[d];&#xD;&#xA;          avg[d] += delta * i_n;&#xD;&#xA;          var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      }&#xD;&#xA;    &#xD;&#xA;      /* Find t dimensions with largest scaled variance. */&#xD;&#xA;      kthLargest(var, points[0].dim(), t, split_dims);&#xD;&#xA;    }";;
66218496;23943004;1329652;5;ce5d0317-e8f2-46bf-a489-5728d524ec6e;2014-05-29 21:14:58.0;"Here's what I would do, in guesstimated order of importance:&#xD;&#xA;&#xD;&#xA;5. Return the floating-point from the `Point` class by value, not by reference.&#xD;&#xA;4. Use `coords[i]` instead of `coords.at(i)`, since you *already* assert that it's within bounds. The `at` member checks the bounds. You only need to check it once.&#xD;&#xA;3. Replace the home-baked error indication/checking in the `Point::operator[]` with an assert. That's what asserts are for, and I doubt that you need to check in release code.&#xD;&#xA;2. Replace the repeated division with a single division and repeated multiplication.&#xD;&#xA;1. Use Adam Bartha's recommendation for `memset`.&#xD;&#xA;&#xD;&#xA;With all this, the `Point::operator[]` will have a chance of getting inlined in the release build and can reduce to two machine instructions (effective address computation and floating point load). That's what you want. Of course it must be *defined* in the header file, otherwise the inlining will only be performed if you enable link-time code generation (a.k.a. LTO).&#xD;&#xA;&#xD;&#xA;Note that the `Point::operator[]`'s body is only equivalent to the single-line&#xD;&#xA;`return coords.at(i)` in a debug build. In a release build the *entire* body is equivalent to `return coords[i]`, **not** `return coords.at(i)`.&#xD;&#xA;&#xD;&#xA;<!-- -->&#xD;&#xA;&#xD;&#xA;    FT Point::operator[](int i) const {&#xD;&#xA;      assert(i >= 0 && i < (int)coords.size());&#xD;&#xA;      return coords[i];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    void compute_variances(size_t t, const std::vector<Point>& points, float* avg,&#xD;&#xA;                           float* var, size_t* split_dims) {&#xD;&#xA;      memset(memset((void*)avg, 0, points[0].dim() * sizeof(float));&#xD;&#xA;    &#xD;&#xA;      for (size_t i = 0; i < points.size(); ++i) {&#xD;&#xA;        float const i_n = 1.0/(1.0 + i);&#xD;&#xA;        for (size_t d = 0; d < points[0].dim(); ++d) {&#xD;&#xA;          float const delta = points[i][d] - avg[d];&#xD;&#xA;          avg[d] += delta * i_n;&#xD;&#xA;          var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      }&#xD;&#xA;    &#xD;&#xA;      /* Find t dimensions with largest scaled variance. */&#xD;&#xA;      kthLargest(var, points[0].dim(), t, split_dims);&#xD;&#xA;    }";;added 228 characters in body
66219188;23943004;1329652;5;3572eb69-bf7e-4d3d-91d2-8226f0fedb7e;2014-05-29 21:28:17.0;"Here's what I would do, in guesstimated order of importance:&#xD;&#xA;&#xD;&#xA;5. Return the floating-point from the `Point` class by value, not by reference.&#xD;&#xA;4. Use `coords[i]` instead of `coords.at(i)`, since you *already* assert that it's within bounds. The `at` member checks the bounds. You only need to check it once.&#xD;&#xA;3. Replace the home-baked error indication/checking in the `Point::operator[]` with an assert. That's what asserts are for, and I doubt that you need to check in release code.&#xD;&#xA;2. Replace the repeated division with a single division and repeated multiplication.&#xD;&#xA;1. Remove the need for wasted initialization by unrolling the first two iterations of the outer loop.&#xD;&#xA;&#xD;&#xA;With all this, the `Point::operator[]` will have a chance of getting inlined in the release build and can reduce to two machine instructions (effective address computation and floating point load). That's what you want. Of course it must be *defined* in the header file, otherwise the inlining will only be performed if you enable link-time code generation (a.k.a. LTO).&#xD;&#xA;&#xD;&#xA;Note that the `Point::operator[]`'s body is only equivalent to the single-line&#xD;&#xA;`return coords.at(i)` in a debug build. In a release build the *entire* body is equivalent to `return coords[i]`, **not** `return coords.at(i)`.&#xD;&#xA;&#xD;&#xA;<!-- -->&#xD;&#xA;&#xD;&#xA;    FT Point::operator[](int i) const {&#xD;&#xA;      assert(i >= 0 && i < (int)coords.size());&#xD;&#xA;      return coords[i];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    void compute_variances(size_t t, const std::vector<Point>& points, float* avg,&#xD;&#xA;                           float* var, size_t* split_dims)&#xD;&#xA;    {&#xD;&#xA;      assert(points.size() > 0);&#xD;&#xA;&#xD;&#xA;      // i = 0, i_n = 1&#xD;&#xA;      assert(points[0].dim() > 0);&#xD;&#xA;      memcpy((void*)avg, (void*)&points[0][0], sizeof(float) * points[0].dim());&#xD;&#xA;&#xD;&#xA;      // i = 1, i_n = 0.5&#xD;&#xA;      if (points.size() >= 2) {&#xD;&#xA;        assert(points[1].dim() == points[0].dim());&#xD;&#xA;        for (size_t d = 0; d < points[0].dim(); ++d) {&#xD;&#xA;          float const delta = points[1][d] - avg[d];&#xD;&#xA;          avg[d] += delta * 0.5;&#xD;&#xA;          var[d] = delta * (points[1][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      }&#xD;&#xA;&#xD;&#xA;      // i = 2, ...&#xD;&#xA;      for (size_t i = 2; i < points.size(); ++i) {&#xD;&#xA;        assert(points[i].dim() == points[0].dim());&#xD;&#xA;        for (size_t d = 0; d < points[0].dim(); ++d) {&#xD;&#xA;          float const delta = points[i][d] - avg[d];&#xD;&#xA;          avg[d] += delta * i_n;&#xD;&#xA;          var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      }&#xD;&#xA;    &#xD;&#xA;      /* Find t dimensions with largest scaled variance. */&#xD;&#xA;      kthLargest(var, points[0].dim(), t, split_dims);&#xD;&#xA;    }";;added 228 characters in body
66219757;23943004;1329652;5;129871d7-0f5c-46a0-9836-eda1a9270090;2014-05-29 21:37:59.0;"Here's what I would do, in guesstimated order of importance:&#xD;&#xA;&#xD;&#xA;5. Return the floating-point from the `Point::operator[]` by value, not by reference.&#xD;&#xA;4. Use `coords[i]` instead of `coords.at(i)`, since you *already* assert that it's within bounds. The `at` member checks the bounds. You only need to check it once.&#xD;&#xA;3. Replace the home-baked error indication/checking in the `Point::operator[]` with an assert. That's what asserts are for. They are nominally no-ops in release mode - I doubt that you need to check it in release code.&#xD;&#xA;2. Replace the repeated division with a single division and repeated multiplication.&#xD;&#xA;1. Remove the need for wasted initialization by unrolling the first two iterations of the outer loop.&#xD;&#xA;0. To lessen impact of cache misses, run the inner loop alternatively forwards then backwards. This at least gives you a chance at using some cached `avg` and `var`. It may in fact remove all cache misses on `avg` and `var` if prefetch works on reverse order of iteration, as it well should.&#xD;&#xA;&#xD;&#xA;The `Point::operator[]` will have a chance of getting inlined in the release build and can reduce to two machine instructions (effective address computation and floating point load). That's what you want. Of course it must be *defined* in the header file, otherwise the inlining will only be performed if you enable link-time code generation (a.k.a. LTO).&#xD;&#xA;&#xD;&#xA;Note that the `Point::operator[]`'s body is only equivalent to the single-line&#xD;&#xA;`return coords.at(i)` in a debug build. In a release build the *entire* body is equivalent to `return coords[i]`, **not** `return coords.at(i)`.&#xD;&#xA;&#xD;&#xA;<!-- -->&#xD;&#xA;&#xD;&#xA;    FT Point::operator[](int i) const {&#xD;&#xA;      assert(i >= 0 && i < (int)coords.size());&#xD;&#xA;      return coords[i];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    void compute_variances(size_t t, const std::vector<Point>& points, float* avg,&#xD;&#xA;                           float* var, size_t* split_dims)&#xD;&#xA;    {&#xD;&#xA;      assert(points.size() > 0);&#xD;&#xA;&#xD;&#xA;      // i = 0, i_n = 1&#xD;&#xA;      assert(points[0].dim() > 0);&#xD;&#xA;      memcpy((void*)avg, (void*)&points[0][0], sizeof(float) * points[0].dim());&#xD;&#xA;&#xD;&#xA;      // i = 1, i_n = 0.5&#xD;&#xA;      if (points.size() >= 2) {&#xD;&#xA;        assert(points[1].dim() == points[0].dim());&#xD;&#xA;        for (size_t d = 0; d < points[0].dim(); ++d) {&#xD;&#xA;          float const delta = points[1][d] - avg[d];&#xD;&#xA;          avg[d] += delta * 0.5;&#xD;&#xA;          var[d] = delta * (points[1][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      } else {&#xD;&#xA;        memset((void*)var, 0, size(float) * points[0].dim());&#xD;&#xA;      }&#xD;&#xA;&#xD;&#xA;      // i = 2, ...&#xD;&#xA;      for (size_t i = 2; i < points.size(); ) {&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0 / (1.0 + i);&#xD;&#xA;          assert(points[i].dim() == points[0].dim());&#xD;&#xA;          for (size_t d = 0; d < points[0].dim(); ++d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;        if (i >= points.size()) break;&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0 / (1.0 + i);&#xD;&#xA;          assert(points[i].dim() == points[0].dim());      &#xD;&#xA;          for (size_t d = points[0].dim() - 1; d >= 0; --d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;      }&#xD;&#xA;    &#xD;&#xA;      /* Find t dimensions with largest scaled variance. */&#xD;&#xA;      kthLargest(var, points[0].dim(), t, split_dims);&#xD;&#xA;    }";;added 228 characters in body
66220079;23943004;1329652;5;e5e59689-5f02-4dc5-9556-587bb3666bae;2014-05-29 21:44:41.0;"Here's what I would do, in guesstimated order of importance:&#xD;&#xA;&#xD;&#xA;5. Return the floating-point from the `Point::operator[]` by value, not by reference.&#xD;&#xA;4. Use `coords[i]` instead of `coords.at(i)`, since you *already* assert that it's within bounds. The `at` member checks the bounds. You only need to check it once.&#xD;&#xA;3. Replace the home-baked error indication/checking in the `Point::operator[]` with an assert. That's what asserts are for. They are nominally no-ops in release mode - I doubt that you need to check it in release code.&#xD;&#xA;2. Replace the repeated division with a single division and repeated multiplication.&#xD;&#xA;1. Remove the need for wasted initialization by unrolling the first two iterations of the outer loop.&#xD;&#xA;0. To lessen impact of cache misses, run the inner loop alternatively forwards then backwards. This at least gives you a chance at using some cached `avg` and `var`. It may in fact remove all cache misses on `avg` and `var` if prefetch works on reverse order of iteration, as it well should.&#xD;&#xA;&#xD;&#xA;The `Point::operator[]` will have a chance of getting inlined in the release build and can reduce to two machine instructions (effective address computation and floating point load). That's what you want. Of course it must be *defined* in the header file, otherwise the inlining will only be performed if you enable link-time code generation (a.k.a. LTO).&#xD;&#xA;&#xD;&#xA;Note that the `Point::operator[]`'s body is only equivalent to the single-line&#xD;&#xA;`return coords.at(i)` in a debug build. In a release build the *entire* body is equivalent to `return coords[i]`, **not** `return coords.at(i)`.&#xD;&#xA;&#xD;&#xA;<!-- -->&#xD;&#xA;&#xD;&#xA;    FT Point::operator[](int i) const {&#xD;&#xA;      assert(i >= 0 && i < (int)coords.size());&#xD;&#xA;      return coords[i];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    const FT * Point::constData() const {&#xD;&#xA;      return &coords[0];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    void compute_variances(size_t t, const std::vector<Point>& points, float* avg,&#xD;&#xA;                           float* var, size_t* split_dims)&#xD;&#xA;    {&#xD;&#xA;      assert(points.size() > 0);&#xD;&#xA;      const size_t D = points[0].dim();&#xD;&#xA;&#xD;&#xA;      // i = 0, i_n = 1&#xD;&#xA;      assert(D > 0);&#xD;&#xA;      memcpy((void*)avg, (void*)points[0].constData(), sizeof(float) * D);&#xD;&#xA;&#xD;&#xA;      // i = 1, i_n = 0.5&#xD;&#xA;      if (points.size() >= 2) {&#xD;&#xA;        assert(points[1].dim() == D);&#xD;&#xA;        for (size_t d = 0; d < D; ++d) {&#xD;&#xA;          float const delta = points[1][d] - avg[d];&#xD;&#xA;          avg[d] += delta * 0.5;&#xD;&#xA;          var[d] = delta * (points[1][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      } else {&#xD;&#xA;        memset((void*)var, 0, sizeof(float) * D);&#xD;&#xA;      }&#xD;&#xA;&#xD;&#xA;      // i = 2, ...&#xD;&#xA;      for (size_t i = 2; i < points.size(); ) {&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0 / (1.0 + i);&#xD;&#xA;          assert(points[i].dim() == D);&#xD;&#xA;          for (size_t d = 0; d < D; ++d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;        if (i >= points.size()) break;&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0 / (1.0 + i);&#xD;&#xA;          assert(points[i].dim() == D);      &#xD;&#xA;          for (size_t d = D - 1; d >= 0; --d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;      }&#xD;&#xA;    &#xD;&#xA;      /* Find t dimensions with largest scaled variance. */&#xD;&#xA;      kthLargest(var, D, t, split_dims);&#xD;&#xA;    }";;added 228 characters in body
66220487;23943004;1329652;5;f3430147-8af6-425c-b3bb-8e26a102365c;2014-05-29 21:53:38.0;"Here's what I would do, in guesstimated order of importance:&#xD;&#xA;&#xD;&#xA;5. Return the floating-point from the `Point::operator[]` by value, not by reference.&#xD;&#xA;4. Use `coords[i]` instead of `coords.at(i)`, since you *already* assert that it's within bounds. The `at` member checks the bounds. You only need to check it once.&#xD;&#xA;3. Replace the home-baked error indication/checking in the `Point::operator[]` with an assert. That's what asserts are for. They are nominally no-ops in release mode - I doubt that you need to check it in release code.&#xD;&#xA;2. Replace the repeated division with a single division and repeated multiplication.&#xD;&#xA;1. Remove the need for wasted initialization by unrolling the first two iterations of the outer loop.&#xD;&#xA;0. To lessen impact of cache misses, run the inner loop alternatively forwards then backwards. This at least gives you a chance at using some cached `avg` and `var`. It may in fact remove all cache misses on `avg` and `var` if prefetch works on reverse order of iteration, as it well should.&#xD;&#xA;&#xD;&#xA;The `Point::operator[]` will have a chance of getting inlined in the release build and can reduce to two machine instructions (effective address computation and floating point load). That's what you want. Of course it must be *defined* in the header file, otherwise the inlining will only be performed if you enable link-time code generation (a.k.a. LTO).&#xD;&#xA;&#xD;&#xA;Note that the `Point::operator[]`'s body is only equivalent to the single-line&#xD;&#xA;`return coords.at(i)` in a debug build. In a release build the *entire* body is equivalent to `return coords[i]`, **not** `return coords.at(i)`.&#xD;&#xA;&#xD;&#xA;<!-- -->&#xD;&#xA;&#xD;&#xA;    FT Point::operator[](int i) const {&#xD;&#xA;      assert(i >= 0 && i < (int)coords.size());&#xD;&#xA;      return coords[i];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    const FT * Point::constData() const {&#xD;&#xA;      return &coords[0];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    void compute_variances(size_t t, const std::vector<Point>& points, float* avg,&#xD;&#xA;                           float* var, size_t* split_dims)&#xD;&#xA;    {&#xD;&#xA;      assert(points.size() > 0);&#xD;&#xA;      const size_t D = points[0].dim();&#xD;&#xA;&#xD;&#xA;      // i = 0, i_n = 1&#xD;&#xA;      assert(D > 0);&#xD;&#xA;      memcpy((void*)avg, (void*)points[0].constData(), sizeof(float) * D);&#xD;&#xA;&#xD;&#xA;      // i = 1, i_n = 0.5&#xD;&#xA;      if (points.size() >= 2) {&#xD;&#xA;        assert(points[1].dim() == D);&#xD;&#xA;        for (size_t d = 0; d < D; ++d) {&#xD;&#xA;          float const delta = points[1][d] - avg[d];&#xD;&#xA;          avg[d] += delta * 0.5;&#xD;&#xA;          var[d] = delta * (points[1][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      } else {&#xD;&#xA;        memset((void*)var, 0, sizeof(float) * D);&#xD;&#xA;      }&#xD;&#xA;&#xD;&#xA;      // i = 2, ...&#xD;&#xA;      for (size_t i = 2; i < points.size(); ) {&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0 / (1.0 + i);&#xD;&#xA;          assert(points[i].dim() == D);&#xD;&#xA;          for (size_t d = 0; d < D; ++d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;        if (i >= points.size()) break;&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0 / (1.0 + i);&#xD;&#xA;          assert(points[i].dim() == D);      &#xD;&#xA;          for (size_t d = D - 1; ; --d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;            if (d == 0) break;&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;      }&#xD;&#xA;    &#xD;&#xA;      /* Find t dimensions with largest scaled variance. */&#xD;&#xA;      kthLargest(var, D, t, split_dims);&#xD;&#xA;    }";;added 26 characters in body
66221170;23943004;1329652;5;33b59133-d9e4-4ccb-b168-64a77afa515a;2014-05-29 22:08:44.0;"Here's what I would do, in guesstimated order of importance:&#xD;&#xA;&#xD;&#xA;5. Return the floating-point from the `Point::operator[]` by value, not by reference.&#xD;&#xA;4. Use `coords[i]` instead of `coords.at(i)`, since you *already* assert that it's within bounds. The `at` member checks the bounds. You only need to check it once.&#xD;&#xA;3. Replace the home-baked error indication/checking in the `Point::operator[]` with an assert. That's what asserts are for. They are nominally no-ops in release mode - I doubt that you need to check it in release code.&#xD;&#xA;2. Replace the repeated division with a single division and repeated multiplication.&#xD;&#xA;1. Remove the need for wasted initialization by unrolling the first two iterations of the outer loop.&#xD;&#xA;0. To lessen impact of cache misses, run the inner loop alternatively forwards then backwards. This at least gives you a chance at using some cached `avg` and `var`. It may in fact remove all cache misses on `avg` and `var` if prefetch works on reverse order of iteration, as it well should.&#xD;&#xA;&#xD;&#xA;The `Point::operator[]` will have a chance of getting inlined in the release build and can reduce to two machine instructions (effective address computation and floating point load). That's what you want. Of course it must be *defined* in the header file, otherwise the inlining will only be performed if you enable link-time code generation (a.k.a. LTO).&#xD;&#xA;&#xD;&#xA;Note that the `Point::operator[]`'s body is only equivalent to the single-line&#xD;&#xA;`return coords.at(i)` in a debug build. In a release build the *entire* body is equivalent to `return coords[i]`, **not** `return coords.at(i)`.&#xD;&#xA;&#xD;&#xA;<!-- -->&#xD;&#xA;&#xD;&#xA;    FT Point::operator[](int i) const {&#xD;&#xA;      assert(i >= 0 && i < (int)coords.size());&#xD;&#xA;      return coords[i];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    const FT * Point::constData() const {&#xD;&#xA;      return &coords[0];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    void compute_variances(size_t t, const std::vector<Point>& points, float* avg,&#xD;&#xA;                           float* var, size_t* split_dims)&#xD;&#xA;    {&#xD;&#xA;      assert(points.size() > 0);&#xD;&#xA;      const size_t D = points[0].dim();&#xD;&#xA;&#xD;&#xA;      // i = 0, i_n = 1&#xD;&#xA;      assert(D > 0);&#xD;&#xA;      memcpy((void*)avg, (void*)points[0].constData(), sizeof(float) * D);&#xD;&#xA;&#xD;&#xA;      // i = 1, i_n = 0.5&#xD;&#xA;      if (points.size() >= 2) {&#xD;&#xA;        assert(points[1].dim() == D);&#xD;&#xA;        for (size_t d = 0; d < D; ++d) {&#xD;&#xA;          float const delta = points[1][d] - avg[d];&#xD;&#xA;          avg[d] += delta * 0.5f;&#xD;&#xA;          var[d] = delta * (points[1][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      } else {&#xD;&#xA;        memset((void*)var, 0, sizeof(float) * D);&#xD;&#xA;      }&#xD;&#xA;&#xD;&#xA;      // i = 2, ...&#xD;&#xA;      for (size_t i = 2; i < points.size(); ) {&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0f / (1.0f + i);&#xD;&#xA;          assert(points[i].dim() == D);&#xD;&#xA;          for (size_t d = 0; d < D; ++d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;        if (i >= points.size()) break;&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0f / (1.0f + i);&#xD;&#xA;          assert(points[i].dim() == D);      &#xD;&#xA;          for (size_t d = D - 1; ; --d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;            if (d == 0) break;&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;      }&#xD;&#xA;    &#xD;&#xA;      /* Find t dimensions with largest scaled variance. */&#xD;&#xA;      kthLargest(var, D, t, split_dims);&#xD;&#xA;    }";;added 5 characters in body
66222434;23943004;1329652;5;3fa50235-293a-4534-9f2f-8c7cd11a616b;2014-05-29 22:41:35.0;"Here's what I would do, in guesstimated order of importance:&#xD;&#xA;&#xD;&#xA;5. Return the floating-point from the `Point::operator[]` by value, not by reference.&#xD;&#xA;4. Use `coords[i]` instead of `coords.at(i)`, since you *already* assert that it's within bounds. The `at` member checks the bounds. You only need to check it once.&#xD;&#xA;3. Replace the home-baked error indication/checking in the `Point::operator[]` with an assert. That's what asserts are for. They are nominally no-ops in release mode - I doubt that you need to check it in release code.&#xD;&#xA;2. Replace the repeated division with a single division and repeated multiplication.&#xD;&#xA;1. Remove the need for wasted initialization by unrolling the first two iterations of the outer loop.&#xD;&#xA;0. To lessen impact of cache misses, run the inner loop alternatively forwards then backwards. This at least gives you a chance at using some cached `avg` and `var`. It may in fact remove all cache misses on `avg` and `var` if prefetch works on reverse order of iteration, as it well should.&#xD;&#xA;1. On modern C++ compilers, the `std::fill` and `std::copy` can leverage type alignment and have a chance at being faster than the C library `memset` and `memcpy`.&#xD;&#xA;&#xD;&#xA;The `Point::operator[]` will have a chance of getting inlined in the release build and can reduce to two machine instructions (effective address computation and floating point load). That's what you want. Of course it must be *defined* in the header file, otherwise the inlining will only be performed if you enable link-time code generation (a.k.a. LTO).&#xD;&#xA;&#xD;&#xA;Note that the `Point::operator[]`'s body is only equivalent to the single-line&#xD;&#xA;`return coords.at(i)` in a debug build. In a release build the *entire* body is equivalent to `return coords[i]`, **not** `return coords.at(i)`.&#xD;&#xA;&#xD;&#xA;<!-- language: lang-c++ -->&#xD;&#xA;&#xD;&#xA;    FT Point::operator[](int i) const {&#xD;&#xA;      assert(i >= 0 && i < (int)coords.size());&#xD;&#xA;      return coords[i];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    const FT * Point::constData() const {&#xD;&#xA;      return &coords[0];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    void compute_variances(size_t t, const std::vector<Point>& points, float* avg,&#xD;&#xA;                           float* var, size_t* split_dims)&#xD;&#xA;    {&#xD;&#xA;      assert(points.size() > 0);&#xD;&#xA;      const size_t D = points[0].dim();&#xD;&#xA;&#xD;&#xA;      // i = 0, i_n = 1&#xD;&#xA;      assert(D > 0);&#xD;&#xA;    #if __cplusplus >= 201103L&#xD;&#xA;      std::copy_n(points[0].constData(), D, avg);&#xD;&#xA;    #else&#xD;&#xA;      std::copy(points[0].constData(), points[0].constData() + D, avg);&#xD;&#xA;    #endif&#xD;&#xA;&#xD;&#xA;      // i = 1, i_n = 0.5&#xD;&#xA;      if (points.size() >= 2) {&#xD;&#xA;        assert(points[1].dim() == D);&#xD;&#xA;        for (size_t d = 0; d < D; ++d) {&#xD;&#xA;          float const delta = points[1][d] - avg[d];&#xD;&#xA;          avg[d] += delta * 0.5f;&#xD;&#xA;          var[d] = delta * (points[1][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      } else {&#xD;&#xA;        std::fill_n(var, D, 0.0f);&#xD;&#xA;      }&#xD;&#xA;&#xD;&#xA;      // i = 2, ...&#xD;&#xA;      for (size_t i = 2; i < points.size(); ) {&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0f / (1.0f + i);&#xD;&#xA;          assert(points[i].dim() == D);&#xD;&#xA;          for (size_t d = 0; d < D; ++d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;        if (i >= points.size()) break;&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0f / (1.0f + i);&#xD;&#xA;          assert(points[i].dim() == D);      &#xD;&#xA;          for (size_t d = D - 1; ; --d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;            if (d == 0) break;&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;      }&#xD;&#xA;    &#xD;&#xA;      /* Find t dimensions with largest scaled variance. */&#xD;&#xA;      kthLargest(var, D, t, split_dims);&#xD;&#xA;    }";;added 272 characters in body
66222752;23943004;1329652;5;ebe7140d-d261-4240-8faa-c40757378389;2014-05-29 22:48:32.0;"Here's what I would do, in guesstimated order of importance:&#xD;&#xA;&#xD;&#xA;5. Return the floating-point from the `Point::operator[]` by value, not by reference.&#xD;&#xA;4. Use `coords[i]` instead of `coords.at(i)`, since you *already* assert that it's within bounds. The `at` member checks the bounds. You only need to check it once.&#xD;&#xA;3. Replace the home-baked error indication/checking in the `Point::operator[]` with an assert. That's what asserts are for. They are nominally no-ops in release mode - I doubt that you need to check it in release code.&#xD;&#xA;2. Replace the repeated division with a single division and repeated multiplication.&#xD;&#xA;1. Remove the need for wasted initialization by unrolling the first two iterations of the outer loop.&#xD;&#xA;0. To lessen impact of cache misses, run the inner loop alternatively forwards then backwards. This at least gives you a chance at using some cached `avg` and `var`. It may in fact remove all cache misses on `avg` and `var` if prefetch works on reverse order of iteration, as it well should.&#xD;&#xA;1. On modern C++ compilers, the `std::fill` and `std::copy` can leverage type alignment and have a chance at being faster than the C library `memset` and `memcpy`.&#xD;&#xA;&#xD;&#xA;The `Point::operator[]` will have a chance of getting inlined in the release build and can reduce to two machine instructions (effective address computation and floating point load). That's what you want. Of course it must be *defined* in the header file, otherwise the inlining will only be performed if you enable link-time code generation (a.k.a. LTO).&#xD;&#xA;&#xD;&#xA;Note that the `Point::operator[]`'s body is only equivalent to the single-line&#xD;&#xA;`return coords.at(i)` in a debug build. In a release build the *entire* body is equivalent to `return coords[i]`, **not** `return coords.at(i)`.&#xD;&#xA;&#xD;&#xA;<!-- language: lang-c++ -->&#xD;&#xA;&#xD;&#xA;    FT Point::operator[](int i) const {&#xD;&#xA;      assert(i >= 0 && i < (int)coords.size());&#xD;&#xA;      return coords[i];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    const FT * Point::constData() const {&#xD;&#xA;      return &coords[0];&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    void compute_variances(size_t t, const std::vector<Point>& points, float* avg,&#xD;&#xA;                           float* var, size_t* split_dims)&#xD;&#xA;    {&#xD;&#xA;      assert(points.size() > 0);&#xD;&#xA;      const int D = points[0].dim();&#xD;&#xA;&#xD;&#xA;      // i = 0, i_n = 1&#xD;&#xA;      assert(D > 0);&#xD;&#xA;    #if __cplusplus >= 201103L&#xD;&#xA;      std::copy_n(points[0].constData(), D, avg);&#xD;&#xA;    #else&#xD;&#xA;      std::copy(points[0].constData(), points[0].constData() + D, avg);&#xD;&#xA;    #endif&#xD;&#xA;&#xD;&#xA;      // i = 1, i_n = 0.5&#xD;&#xA;      if (points.size() >= 2) {&#xD;&#xA;        assert(points[1].dim() == D);&#xD;&#xA;        for (int d = D - 1; d >= 0; --d) {&#xD;&#xA;          float const delta = points[1][d] - avg[d];&#xD;&#xA;          avg[d] += delta * 0.5f;&#xD;&#xA;          var[d] = delta * (points[1][d] - avg[d]);&#xD;&#xA;        }&#xD;&#xA;      } else {&#xD;&#xA;        std::fill_n(var, D, 0.0f);&#xD;&#xA;      }&#xD;&#xA;&#xD;&#xA;      // i = 2, ...&#xD;&#xA;      for (size_t i = 2; i < points.size(); ) {&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0f / (1.0f + i);&#xD;&#xA;          assert(points[i].dim() == D);&#xD;&#xA;          for (int d = 0; d < D; ++d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;        if (i >= points.size()) break;&#xD;&#xA;        {&#xD;&#xA;          const float i_n = 1.0f / (1.0f + i);&#xD;&#xA;          assert(points[i].dim() == D);      &#xD;&#xA;          for (int d = D - 1; d >= 0; --d) {&#xD;&#xA;            float const delta = points[i][d] - avg[d];&#xD;&#xA;            avg[d] += delta * i_n;&#xD;&#xA;            var[d] += delta * (points[i][d] - avg[d]);&#xD;&#xA;          }&#xD;&#xA;        }&#xD;&#xA;        ++ i;&#xD;&#xA;      }&#xD;&#xA;    &#xD;&#xA;      /* Find t dimensions with largest scaled variance. */&#xD;&#xA;      kthLargest(var, D, t, split_dims);&#xD;&#xA;    }";;added 272 characters in body
